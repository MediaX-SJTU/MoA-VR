<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration">
  <meta property="og:title" content="MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration"/>
  <meta property="og:description" content="MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration"/>
  <meta property="og:url" content="https://mediax-sjtu.github.io/MoA-VR-projectpage/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration">
  <meta name="twitter:description" content="MoRF avatars are created from short monocular videos and can be rendered in real-time (30+ FPS, 640x640px) on mobile devices">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h1 class="title is-1 publication-title">
              <a style="color:black;">MoA-VR</a>: A Mixture-of-Agents System Towards All-in-One Video Restoration<a style="color:black;"></a> </h1> -->
<h1 class="title is-1 publication-title"><a style="color:black;font-weight:bold; font-style:italic;">MoA-VR</a>: <a style="color:black;"> A Mixture-of-Agents System Towards All-in-One Video Restoration</a> </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Lu Liu<sup>1</sup>,</span>
              <span class="author-block">Chunlei Cai<sup>2</sup>,</span>
              <span class="author-block">Shaocheng Shen<sup>1</sup>,</span>
              <span class="author-block">Jianfeng Liang<sup>1</sup>,</span>
              <span class="author-block">Weimin Ouyang<sup>1</sup>,</span>
              <span class="author-block">Tianxiao Ye<sup>2</sup>,</span>
              <span class="author-block">Jian Mao<sup>2</sup>,</span>
              <span class="author-block">Huiyu Duan<sup>1</sup>,</span>
              <span class="author-block">Jiangchao Yao<sup>1</sup>,</span>
              <span class="author-block">Xiaoyun Zhang<sup>1</sup>,</span>
              <span class="author-block">Qiang Hu,*<sup>1</sup>,</span>
              <span class="author-block">Guangtao Zhai<sup>1</sup></span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
              <span class="author-block"><sup>2</sup>Bilibili Inc.</span>
            </div>
            <div class="is-size-5 has-text-centered" style="margin-top: 0.5rem;">
  <!-- <strong style="color:#86d2dc; font-size: 1.1em;"></strong> -->
</div>

                  <!-- ArXiv Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2510.08508" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                  <!-- <span class="link-block">
                    <a href="https://arxiv.org/abs/2510.08508" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/MediaX-SJTU/MoA-VR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>

                  <br>

                
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <center>
      <img src="static/images/0.png" alt="Method"/>
      <h2 class="subtitle has-text-centered">
         Overview of the agents in MoA-VR. MoA-VR restores low-quality
video clips with complex degradations through the collaboration of three
agents: the degradation identification agent, the routing and restoration agent,
and the quality assessment agent.
      </h2>
    </center>
    </div>
  </div>
</section>

<!-- <video poster="" id="steve" autoplay controls muted loop playsinline height="100%"> -->

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-chair-t">
        <center>
          <video poster="" id="chair-t" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_1.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-chair-tp">
        <center>
          <video poster="" id="chair-tp" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_0.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-shiba">
        <center>
          <video poster="" id="shiba" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_2.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-fullbody">
        <center>
          <video poster="" id="fullbody" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_9.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-blueshirt">
        <center>
          <video poster="" id="blueshirt" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_16.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-mask">
        <center>
          <video poster="" id="mask" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_11.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-coffee">
        <center>
          <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_3.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-coffee">
          <center>
            <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
              <source src="./static/videos/output_13.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
        <div class="item item-coffee">
          <center>
            <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
              <source src="./static/videos/output_4.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="hero-body has-text-justified">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="container">
          
          <br>
        </div>
        <div class="container">
         Real-world videos often suffer from complex degra- dations, such as noise, compression artifacts, and low-light distortions, due to diverse acquisition and transmission conditions. Existing restoration methods typically require professional manual selection of specialized models or rely on monolithic architectures that fail to generalize across varying degradations. Inspired by expert experience, we propose MoA-VR, the first Mixture-of-Agents Video Restoration system that mimics the reasoning and processing procedures of human professionals through three coordinated agents: Degradation Identification, Routing and Restoration, and Restoration Quality Assessment. Specifically, we construct a large-scale and high-resolution video degradation recognition benchmark and build a vision-language model (VLM) driven degradation identifier. We further introduce a self-adaptive router powered by large language models (LLMs), which autonomously learns effective restoration strategies by observing tool usage patterns. To assess intermediate and final processed video quality, we construct the Restored Video Quality (Res-VQ) dataset and design a dedicated VLM-based video quality assessment (VQA) model tailored for restoration tasks. Extensive experiments demonstrate that MoA-VR effectively handles diverse and compound degradations, consistently out- performing existing baselines in terms of both objective metrics and perceptual quality. These results highlight the potential of integrating multimodal intelligence and modular reasoning in general-purpose video restoration systems.
          <br>
          <br>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Teaser video-->
<section class="hero teaser">
  <div class="hero-body has-text-justified">
    <div class="container is-max-desktop">
      <div class="hero-body">


        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Degradation Identification Agent Ai</h2>
        <div class="container">
          The overall framework of Ai. Ai can evaluate all types of degradation levels in an all-in-one framework. It can process videos, along with prompts, to identify the degradations. It consists of a vision encoder to extract both spatial and temporal features and a text tokenizer to tokenize the input prompts. These features are projected into the same space by trained projectors. A pre-trained LLM is utilized to fuse the features while fine-tuned with LoRA.
          <br>
          <br>
        </div>
        <div class="has-text-centered">
        <img src="static/images/1.png" alt="Method"/>
        </div>
        <br>
        <br>
        <br>

         <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Routing and Restoration Agent Ar</h2>
        <div class="container">
          Illumination of degradation removal process by Routing and Restoration Agent Ar. Ar is able to route the degradation removal orders, rollback when restoration fails, reroute to another degradation removal orders.
          <br>
          <br>
        </div>
        <div class="has-text-centered">
        <img src="static/images/2.png" alt="Method"/>
        </div>
        <!-- <img src="static/images/4.png" alt="Method"/>
        <img src="static/images/5.png" alt="Another Image"/> -->
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Quality Assessment Agent Aa</h2>
        <div class="container">
          An overview of quality assessment agent Aa. It consists of three feature encoders, including an image feature extractor for extracting spatial features from sparse video frames, a motion feature extractor for extracting motion features from the entire video, and a text encoder for extracting aligned text features from prompts. The extracted features are then aligned through projectors and fed into a pre-trained LLM to generate the output results. LoRA weights are introduced to the pre-trained image encoder and the large language model to adapt the models to the quality assessment task.

          <br>
          <br>
        </div>
        <img src="static/images/3.png" alt="Method"/>
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Agent Collaboration and Closed-Loop Design</h2>
        <div class="container">
          MoA-VR incorporates three specialized agents within a closed-loop architecture. For a low-quality input video, Ai identifies the degradation type and level; Ar generates a degradation removal plan and then invokes the corresponding restoration toolbox; Aa assesses all the intermediate results and chooses the best quality one. Then Ai identifies whether the previous restoration was successful. If it fails, Ar rolls back and reroutes; if successful, Ar follows the previous plan. This loop continues until all degradations are removed.
          <br>
          <br>
        </div>
        <img src="static/images/4.png" alt="Method"/>
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Performance on restoration task</h2>
        <div class="container">
          Performance comparison between state-of-the-art all-in-one methods.
          <br>
          <br>
        </div>
        <img src="static/images/5.png" alt="Method"/>
        <img src="static/images/6.png" alt="Method"/>
        <br>
        <br>
        <br>
        <!-- <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Performance on Other VQA databases</h2>
        <div class="container">
          Performance comparison between state-of-the-art VQA methods and the proposed FineVQ on six UGC VQA databases
          <br>
          <br>
        </div>
        <img src="static/images/8.png" alt="Method"/>
        <br>
        <br>
        <br> -->
        <br>
<br>
<br>
<h2 class="title has-text-centered">Performance of different agents</h2>
<div class="container">
  Evaluation of degradation identification agent, routing and restoration agent and quality assessment agent..
  <br><br>
</div>

<!-- 两张图并列 -->
<!-- <div class="columns is-centered">
  <div class="column is-half has-text-centered">
    <img src="static/images/7.png" alt="Method 1" style="max-width: 90%;">
  </div>
  <div class="column is-half has-text-centered">
    <img src="static/images/8.png" alt="Method 2" style="max-width: 130%;">
  </div>
  <div class="column is-half has-text-centered">
    <img src="static/images/9.png" alt="Method 2" style="max-width: 50%;">
  </div>
</div> -->
<!-- <div class="columns is-centered">
  <div class="column is-half has-text-centered">
    <img src="static/images/7.png" alt="Method 1" style="max-width: 100%; width: 100%; display: block; margin: 0 auto;">
  </div>
  <div class="column is-half has-text-centered">
    <img src="static/images/8.png" alt="Method 2" style="max-width: 100%; width: 100%; display: block; margin: 0 auto;">
  </div>
  <div class="column is-flex is-half">
    <img src="static/images/9.png" alt="Method 3" style="max-width: 50%; width: 50%; display: block; margin: 0 auto;">
  </div>
</div> -->
<div class="columns is-centered">
  <div class="column is-one-third has-text-centered" style="padding: 0;">
    <img src="static/images/7.png" alt="Method 1" style="max-width: 100%; width: 100%; display: block; margin: 0 auto;">
  </div>
  <div class="column is-one-third has-text-centered" style="padding: 0;">
    <img src="static/images/8.png" alt="Method 2" style="max-width: 100%; width: 100%; display: block; margin: 0 auto;">
  </div>
  <div class="column is-one-third has-text-centered" style="padding: 0;">
    <img src="static/images/9.png" alt="Method 3" style="max-width: 100%; width: 50%; display: block; margin: 0 auto;">
  </div>
</div>



<br>
<br>
<br>



        
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <
    </div>
  </div>
</section> -->


<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!-- <br>
<br>
<br>
<br>
<h2 class="title has-text-centered">Qualitative Novel View Results</h2>

<div class="container">
  Our method also has the capability to produce realistic novel views of multiple objects. Using the Rotation + SAM + Inpaint parts of our method, we show qualitative results of our methods ability to generate novel views given an RGB-D image.
  <br>
  <br>
</div>
<img src="static/images/Inpainted_Qualitative.png" alt="Method"/>


<br>
<br>
<br>
<br> -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{liu2025moavrmixtureofagentsallinonevideo,
      title={MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration}, 
      author={Lu Liu and Chunlei Cai and Shaocheng Shen and Jianfeng Liang and Weimin Ouyang and Tianxiao Ye and Jian Mao and Huiyu Duan and Jiangchao Yao and Xiaoyun Zhang and Qiang Hu and Guangtao Zhai},
      year={2025},
      eprint={2510.08508},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.08508}, 
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->






  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://licensebuttons.net/l/by-nc/3.0/88x31.png"/>
            </a><br />This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0">Creative Commons Attribution-NonCommercial 4.0 International License</a> (CC-BY-NC).
          </p>
          <p>
            This webpage is built with the template from <a
                  href="https://github.com/nerfies/nerfies.github.io" target="_blank">NeRFies</a>. We sincerely thank <a href="https://keunhong.com/" target="_blank">Keunhong Park</a> for developing and open-sourcing this template.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
